checkpointing.interval = 1000
job.parallelism = 1
kafka = {
  format = "kafka"
  topic = "test3"
  bootstrap.servers = "kafka:9092"
  group_id = "spark-group"
  failOnDataLoss = "false"
  scan.startup.mode = "earliest-offset"
}
ms_ip = {
  format = "jdbc"
  url = "jdbc:postgresql://host.docker.internal:5432/diploma"
  dbtable = "public.ms_ip"
  user = "postgres"
  password = "7844"
}

imsi_msisdn = {
  format = "jdbc"
  url = "jdbc:postgresql://host.docker.internal:5432/diploma"
  dbtable = "public.imsi_msisdn"
  user = "postgres"
  password = "7844"
}

hdfs = {
    name = "hdfs_sink"
    partitionBy = ["event_date", "probe"]
    blockSizeMB = 128
    format = "parquet"
    path = "hdfs://namenode:8020/spark/results"
    checkpointLocation = "hdfs://namenode:8020/spark/checkpoints"
}
